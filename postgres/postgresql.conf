# PostgreSQL 17 Configuration File - Production Settings
# WildDuck Mail Box Indexer
#
# Server Configuration:
# - Total RAM: 128GB (96GB available for native services after VMware allocation)
# - Storage: 10TB RAID6 SSD (very fast, optimized for high IOPS)
# - PostgreSQL allocation: ~48GB RAM (50% of available native RAM)
# - MongoDB will use remaining ~48GB RAM

#------------------------------------------------------------------------------
# FILE LOCATIONS
#------------------------------------------------------------------------------

# These paths are for Windows installation
# Default: C:\PostgreSQL\data or C:\Program Files\PostgreSQL\17\data
# data_directory = 'C:/PostgreSQL/data'
# hba_file = 'C:/PostgreSQL/data/pg_hba.conf'
# ident_file = 'C:/PostgreSQL/data/pg_ident.conf'

#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------

# Listen on all network interfaces (change to specific IP for more security)
# For localhost only: listen_addresses = 'localhost'
# For specific IP: listen_addresses = 'localhost,192.168.1.100'
listen_addresses = '*'

# Port number
port = 5432

# Maximum number of concurrent connections
# Adjust based on expected load
# Each connection uses ~10MB RAM
# For high-capacity server: 500 connections
max_connections = 500

# Reserved connections for superuser
superuser_reserved_connections = 3

#------------------------------------------------------------------------------
# RESOURCE USAGE (except WAL)
#------------------------------------------------------------------------------

# --- Memory ---

# shared_buffers: Amount of memory dedicated to PostgreSQL cache
# Recommended: 25% of total RAM for dedicated database server
# For 96GB available RAM: 24GB (25% of 96GB)
# This allows PostgreSQL to cache hot data effectively
shared_buffers = 24GB

# huge_pages: Use huge pages if available (improves performance)
# Windows: try, Linux: try
huge_pages = try

# work_mem: Memory per query operation (sort, hash join)
# WARNING: Each complex query can use multiple times this amount
# Max total memory = max_connections * work_mem * avg_operations_per_query
# For 96GB RAM with 500 connections: 64MB
# 500 connections × 64MB × 2 operations = ~64GB max (safe buffer)
work_mem = 64MB

# maintenance_work_mem: Memory for maintenance operations (VACUUM, CREATE INDEX)
# Recommended: 5-10% of total RAM, max 4GB for large databases
# For 96GB RAM: 4GB (allows faster index creation and vacuuming)
maintenance_work_mem = 4GB

# autovacuum_work_mem: Memory for autovacuum workers
# -1 means use maintenance_work_mem
autovacuum_work_mem = -1

# logical_decoding_work_mem: Memory for logical decoding
logical_decoding_work_mem = 64MB

# max_stack_depth: Maximum stack depth (should be less than kernel limit)
# Windows default is fine
max_stack_depth = 2MB

# --- Disk ---

# temp_file_limit: Maximum size of temporary files per session
# -1 = unlimited (default)
# Set limit to prevent runaway queries from filling disk
# For 10TB storage: 50GB per session is safe
temp_file_limit = 50GB

#------------------------------------------------------------------------------
# WRITE-AHEAD LOG
#------------------------------------------------------------------------------

# --- Settings ---

# WAL level for replication (if needed in future)
# minimal: No replication support
# replica: Support streaming replication
# logical: Support logical replication
wal_level = replica

# fsync: Force writes to disk for durability
# NEVER turn off in production!
fsync = on

# synchronous_commit: Wait for WAL write before confirming transaction
# on = safest, off = faster but risk of data loss
# local = good compromise
synchronous_commit = on

# wal_sync_method: Method to force WAL writes to disk
# Windows: fsync or fsync_writethrough
wal_sync_method = fsync

# full_page_writes: Write full pages to WAL after checkpoint
# Required for crash recovery, keep on
full_page_writes = on

# wal_buffers: WAL buffer size
# Recommended: 3% of shared_buffers, min 16MB, max 64MB
# For shared_buffers = 24GB: 64MB
wal_buffers = 64MB

# wal_writer_delay: Delay between WAL writer rounds
wal_writer_delay = 200ms

# --- Checkpoints ---

# checkpoint_timeout: Maximum time between checkpoints
checkpoint_timeout = 15min

# checkpoint_completion_target: Spread checkpoint I/O
# 0.9 = spread over 90% of checkpoint_timeout
# Reduces I/O spikes
checkpoint_completion_target = 0.9

# checkpoint_flush_after: Flush to disk after this much data
# For RAID6 SSD: Can be larger due to fast writes and good I/O handling
checkpoint_flush_after = 2MB

# checkpoint_warning: Warn if checkpoints happen too frequently
checkpoint_warning = 30s

# --- Archiving (for backups and replication) ---

# max_wal_size: Maximum WAL size between checkpoints
# Larger = fewer checkpoints but more recovery time
# For 10TB storage and high-capacity server: 16GB
max_wal_size = 16GB

# min_wal_size: Minimum WAL size to keep
# Should be at least 2x the size written during checkpoint_timeout
# For high-capacity server: 4GB
min_wal_size = 4GB

# archive_mode: Enable WAL archiving for point-in-time recovery
# off = disabled, on = enabled, always = enabled even on standby
# Enable this when setting up backups
archive_mode = off

# archive_command: Command to archive a WAL file
# Example for Windows:
# archive_command = 'copy "%p" "C:\\PostgreSQL\\archives\\%f"'
archive_command = ''

# archive_timeout: Force WAL segment switch after this time
archive_timeout = 0

#------------------------------------------------------------------------------
# REPLICATION
#------------------------------------------------------------------------------

# max_wal_senders: Maximum WAL sender processes
# Set > 0 if you plan to add read replicas
max_wal_senders = 0

# max_replication_slots: Maximum replication slots
max_replication_slots = 0

# wal_keep_size: Minimum WAL size to keep for replication
wal_keep_size = 0

#------------------------------------------------------------------------------
# QUERY TUNING
#------------------------------------------------------------------------------

# --- Planner Cost Constants ---

# random_page_cost: Cost of random disk page fetch
# Default 4.0 is for HDD
# For RAID6 SSD: 1.0-1.1 (very fast, SSDs eliminate seek time penalty)
# RAID6 SSD has excellent random read performance
random_page_cost = 1.0

# seq_page_cost: Cost of sequential disk page fetch
# Usually 1.0, no need to change
seq_page_cost = 1.0

# cpu_tuple_cost: Cost of processing each row
cpu_tuple_cost = 0.01

# cpu_index_tuple_cost: Cost of processing each index entry
cpu_index_tuple_cost = 0.005

# cpu_operator_cost: Cost of processing each operator/function
cpu_operator_cost = 0.0025

# effective_cache_size: Estimate of OS and PostgreSQL cache
# Recommended: 50-75% of total RAM
# This is NOT allocated memory, just a hint to query planner
# For 96GB RAM: 72GB (75% of available RAM)
effective_cache_size = 72GB

# effective_io_concurrency: Number of simultaneous I/O operations
# For RAID6 SSD: Can be much higher due to SSD parallelism
# SSDs can handle many concurrent operations efficiently
# For RAID6 SSD: 200-400 (similar to single SSD but with RAID parallelism)
effective_io_concurrency = 300

# --- Genetic Query Optimizer ---

# geqo: Use genetic query optimization for complex queries
geqo = on
geqo_threshold = 12

# --- Other Planner Options ---

# default_statistics_target: Statistics detail for planner
# Higher = better plans but slower ANALYZE
# Default: 100, increase for complex queries
default_statistics_target = 100

#------------------------------------------------------------------------------
# PARALLEL QUERIES
#------------------------------------------------------------------------------

# max_worker_processes: Maximum background processes
# For high-capacity server with many cores: 16
max_worker_processes = 16

# max_parallel_workers_per_gather: Max workers per Gather node
# For high-capacity server: 8 (increased parallelism for complex queries)
max_parallel_workers_per_gather = 8

# max_parallel_maintenance_workers: Max workers for maintenance
# For CREATE INDEX, VACUUM on large tables: 8
max_parallel_maintenance_workers = 8

# max_parallel_workers: Total parallel workers
# Should be <= max_worker_processes
max_parallel_workers = 16

# parallel_leader_participation: Leader process participates in parallel query
parallel_leader_participation = on

# min_parallel_table_scan_size: Minimum table size for parallel scan
min_parallel_table_scan_size = 8MB

# min_parallel_index_scan_size: Minimum index size for parallel scan
min_parallel_index_scan_size = 512kB

#------------------------------------------------------------------------------
# LOGGING
#------------------------------------------------------------------------------

# --- Where to Log ---

# log_destination: Where to send logs
# Windows: stderr, eventlog
# This config uses logging_collector for file-based logging
log_destination = 'stderr'

# logging_collector: Enable background log collector process
# Captures stderr output and writes to files
logging_collector = on

# log_directory: Directory for log files
# Relative to data directory
log_directory = 'log'

# log_filename: Log file name pattern
# %Y = year, %m = month, %d = day, %H = hour, %M = minute, %S = second
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'

# log_file_mode: Permissions for log files
log_file_mode = 0600

# log_rotation_age: Rotate log after this time
# For minimal disk usage: rotate daily and overwrite old logs
log_rotation_age = 1d

# log_rotation_size: Rotate log after this size
# For minimal disk usage: disabled (rely on time-based rotation)
log_rotation_size = 0

# log_truncate_on_rotation: Overwrite old log file
# ON = overwrite old logs to save disk space (keeps only 1 day of logs)
log_truncate_on_rotation = on

# --- When to Log ---

# log_min_messages: Minimum severity to log
# debug5, debug4, debug3, debug2, debug1, info, notice, warning, error, log, fatal, panic
log_min_messages = warning

# log_min_error_statement: Log statements causing errors at this level
log_min_error_statement = error

# log_min_duration_statement: Log statements running longer than this
# -1 = disabled, 0 = all, 1000 = statements taking > 1 second
# For minimal disk usage: 5000ms (only very slow queries)
log_min_duration_statement = 5000

# log_min_duration_sample: Sample statements for logging
log_min_duration_sample = -1

# log_statement_sample_rate: Fraction of statements to log
log_statement_sample_rate = 1.0

# log_transaction_sample_rate: Fraction of transactions to log
log_transaction_sample_rate = 0.0

# --- What to Log ---

# log_checkpoints: Log checkpoint activity
# OFF for minimal disk usage (enable only for troubleshooting)
log_checkpoints = off

# log_connections: Log each connection
# OFF for minimal disk usage (with 500 max connections, this creates huge logs)
log_connections = off

# log_disconnections: Log session disconnections
# OFF for minimal disk usage
log_disconnections = off

# log_duration: Log duration of each completed statement
log_duration = off

# log_error_verbosity: Amount of detail in error messages
# terse, default, verbose
log_error_verbosity = default

# log_hostname: Log hostname in connection logs
# Can slow down connections, usually off
log_hostname = off

# log_line_prefix: Prefix for each log line
# %t = timestamp, %p = process ID, %l = log line number
# %u = user, %d = database, %a = application, %h = host, %c = session ID
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# log_lock_waits: Log lock waits longer than deadlock_timeout
log_lock_waits = on

# log_recovery_conflict_waits: Log recovery conflicts
log_recovery_conflict_waits = on

# log_statement: Log statements
# none, ddl, mod, all
# For production: 'ddl' logs schema changes
log_statement = 'ddl'

# log_replication_commands: Log replication commands
log_replication_commands = off

# log_temp_files: Log temporary files larger than this size
# -1 = disabled, 0 = all, 10MB = log temp files > 10MB
# For RAID6 SSD: Higher threshold since temp files are less of a concern
# SSDs handle temp file I/O efficiently
log_temp_files = 100MB

# log_timezone: Timezone for log timestamps
log_timezone = 'America/Los_Angeles'

#------------------------------------------------------------------------------
# PROCESS TITLE
#------------------------------------------------------------------------------

# cluster_name: Cluster name in process titles
cluster_name = 'mail_box_indexer'

# update_process_title: Update process title to show activity
update_process_title = on

#------------------------------------------------------------------------------
# STATISTICS
#------------------------------------------------------------------------------

# --- Planner Statistics ---

# track_activities: Collect current command information
track_activities = on

# track_activity_query_size: Size of current query text
# Increase for longer queries
track_activity_query_size = 2048

# track_counts: Collect statistics on table/index access
track_counts = on

# track_io_timing: Collect I/O timing statistics
# Slight overhead but very useful for performance tuning
track_io_timing = on

# track_wal_io_timing: Collect WAL I/O timing
track_wal_io_timing = on

# track_functions: Track function call counts and times
# none, pl (PL/pgSQL only), all
track_functions = none

# stats_fetch_consistency: Consistency of statistics snapshot
# none, cache, snapshot
stats_fetch_consistency = cache

# --- Monitoring ---

# compute_query_id: Compute query ID for monitoring
# auto, on, off, regress
compute_query_id = auto

# log_statement_stats: Log total statement performance stats
log_statement_stats = off

# log_parser_stats: Log parser performance stats
log_parser_stats = off

# log_planner_stats: Log planner performance stats
log_planner_stats = off

# log_executor_stats: Log executor performance stats
log_executor_stats = off

#------------------------------------------------------------------------------
# AUTOVACUUM
#------------------------------------------------------------------------------

# autovacuum: Enable autovacuum daemon
# CRITICAL: Keep this ON in production!
autovacuum = on

# autovacuum_max_workers: Maximum autovacuum worker processes
# Recommended: 3-5 for busy systems
autovacuum_max_workers = 3

# autovacuum_naptime: Delay between autovacuum runs
# Lower = more frequent vacuuming
autovacuum_naptime = 1min

# autovacuum_vacuum_threshold: Minimum dead tuples before vacuum
autovacuum_vacuum_threshold = 50

# autovacuum_vacuum_insert_threshold: Minimum inserts before vacuum
autovacuum_vacuum_insert_threshold = 1000

# autovacuum_analyze_threshold: Minimum changed tuples before analyze
autovacuum_analyze_threshold = 50

# autovacuum_vacuum_scale_factor: Fraction of table size before vacuum
# 0.2 = vacuum when 20% of tuples are dead
autovacuum_vacuum_scale_factor = 0.2

# autovacuum_vacuum_insert_scale_factor: Fraction for insert-only tables
autovacuum_vacuum_insert_scale_factor = 0.2

# autovacuum_analyze_scale_factor: Fraction before analyze
autovacuum_analyze_scale_factor = 0.1

# autovacuum_freeze_max_age: Maximum age before forced vacuum
autovacuum_freeze_max_age = 200000000

# autovacuum_multixact_freeze_max_age: Maximum multixact age
autovacuum_multixact_freeze_max_age = 400000000

# autovacuum_vacuum_cost_delay: Delay between vacuum cost cycles
# Lower = faster but more I/O impact
# 2ms is balanced for production
autovacuum_vacuum_cost_delay = 2ms

# autovacuum_vacuum_cost_limit: Vacuum cost limit
# Higher = faster vacuum but more I/O
autovacuum_vacuum_cost_limit = 200

#------------------------------------------------------------------------------
# CLIENT CONNECTION DEFAULTS
#------------------------------------------------------------------------------

# --- Statement Behavior ---

# client_min_messages: Client message level
# debug5, debug4, debug3, debug2, debug1, log, notice, warning, error
client_min_messages = notice

# search_path: Schema search order
search_path = '"$user", public'

# row_security: Enable row security
row_security = on

# default_table_access_method: Default table storage
default_table_access_method = heap

# default_tablespace: Default tablespace for objects
default_tablespace = ''

# default_toast_compression: Default compression for TOAST
# pglz or lz4
default_toast_compression = pglz

# temp_tablespaces: Tablespaces for temporary objects
temp_tablespaces = ''

# check_function_bodies: Check function bodies during CREATE FUNCTION
check_function_bodies = on

# default_transaction_isolation: Default isolation level
# 'serializable', 'repeatable read', 'read committed', 'read uncommitted'
default_transaction_isolation = 'read committed'

# default_transaction_read_only: Default read-only mode
default_transaction_read_only = off

# default_transaction_deferrable: Default deferrable mode
default_transaction_deferrable = off

# session_replication_role: Session replication role
# origin, replica, local
session_replication_role = 'origin'

# statement_timeout: Maximum statement execution time
# 0 = unlimited (default)
# For production: 30000 (30 seconds) prevents runaway queries
# Adjust based on your slowest expected query
statement_timeout = 30000

# lock_timeout: Maximum time to wait for a lock
# 0 = unlimited
# For web applications: 3000-5000ms
lock_timeout = 0

# idle_in_transaction_session_timeout: Timeout for idle transactions
# 0 = unlimited
# Recommended: 60000 (60 seconds) to prevent connection pool exhaustion
idle_in_transaction_session_timeout = 60000

# idle_session_timeout: Timeout for idle sessions
# 0 = unlimited
# Optional: 600000 (10 minutes)
idle_session_timeout = 0

# vacuum_freeze_min_age: Minimum age for freezing tuples
vacuum_freeze_min_age = 50000000

# vacuum_freeze_table_age: Age at which VACUUM scans whole table
vacuum_freeze_table_age = 150000000

# vacuum_multixact_freeze_min_age: Minimum multixact age for freezing
vacuum_multixact_freeze_min_age = 5000000

# vacuum_multixact_freeze_table_age: Multixact age for whole table scan
vacuum_multixact_freeze_table_age = 150000000

# vacuum_failsafe_age: Age at which VACUUM enters failsafe mode
vacuum_failsafe_age = 1600000000

# vacuum_multixact_failsafe_age: Multixact age for failsafe
vacuum_multixact_failsafe_age = 1600000000

# bytea_output: Format for bytea output
# hex or escape
bytea_output = 'hex'

# xmlbinary: Format for binary XML
# base64 or hex
xmlbinary = 'base64'

# xmloption: XML conformance level
# document or content
xmloption = 'content'

# gin_pending_list_limit: Maximum size of GIN pending list
gin_pending_list_limit = 4MB

# --- Locale and Formatting ---

# datestyle: Date/time output format
datestyle = 'iso, mdy'

# intervalstyle: Interval output format
# postgres, postgres_verbose, sql_standard, iso_8601
intervalstyle = 'postgres'

# timezone: Timezone for timestamps
# Use your server's timezone
timezone = 'America/Los_Angeles'

# timezone_abbreviations: Timezone abbreviations set
timezone_abbreviations = 'Default'

# extra_float_digits: Extra digits for float output
extra_float_digits = 1

# --- Shared Library Preloading ---

# shared_preload_libraries: Libraries to preload
# pg_stat_statements is essential for query monitoring
# Add others as needed: 'pg_stat_statements, auto_explain'
shared_preload_libraries = 'pg_stat_statements'

# --- Other Defaults ---

# dynamic_library_path: Path for dynamic libraries
dynamic_library_path = '$libdir'

# gin_fuzzy_search_limit: Maximum results for GIN fuzzy search
gin_fuzzy_search_limit = 0

#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

# deadlock_timeout: Time to wait before checking for deadlock
deadlock_timeout = 1s

# max_locks_per_transaction: Max locks per transaction
# Increase if you see "out of shared memory" errors
max_locks_per_transaction = 64

# max_pred_locks_per_transaction: Max predicate locks per transaction
max_pred_locks_per_transaction = 64

# max_pred_locks_per_relation: Max predicate locks per relation
max_pred_locks_per_relation = -2

# max_pred_locks_per_page: Max predicate locks per page
max_pred_locks_per_page = 2

#------------------------------------------------------------------------------
# VERSION AND PLATFORM COMPATIBILITY
#------------------------------------------------------------------------------

# array_nulls: Enable NULL elements in arrays
array_nulls = on

# backslash_quote: Allow backslash in quotes
# safe_encoding, on, off
backslash_quote = safe_encoding

# escape_string_warning: Warn about backslash escapes in ordinary strings
escape_string_warning = on

# lo_compat_privileges: Use old large object privilege checking
lo_compat_privileges = off

# quote_all_identifiers: Quote all identifiers in SQL dumps
quote_all_identifiers = off

# standard_conforming_strings: Treat backslashes literally
standard_conforming_strings = on

# synchronize_seqscans: Enable synchronized sequential scans
synchronize_seqscans = on

#------------------------------------------------------------------------------
# ERROR HANDLING
#------------------------------------------------------------------------------

# exit_on_error: Terminate session on error
exit_on_error = off

# restart_after_crash: Restart after backend crash
restart_after_crash = on

# data_sync_retry: Retry failed fsync operations
data_sync_retry = off

# recovery_init_sync_method: Method for initial sync during recovery
# fsync or syncfs
recovery_init_sync_method = fsync

#------------------------------------------------------------------------------
# CUSTOMIZED OPTIONS
#------------------------------------------------------------------------------

# pg_stat_statements configuration
# Requires: shared_preload_libraries = 'pg_stat_statements'
# After setting this, run: CREATE EXTENSION pg_stat_statements;
pg_stat_statements.max = 10000
pg_stat_statements.track = all
pg_stat_statements.track_utility = on
pg_stat_statements.save = on

#------------------------------------------------------------------------------
# INCLUDE FILES
#------------------------------------------------------------------------------

# Include files from conf.d directory (if exists)
# include_dir = 'conf.d'

# Include specific file
# include = 'custom.conf'

# Include if exists (won't error if missing)
# include_if_exists = 'optional.conf'
